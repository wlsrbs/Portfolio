{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bax/anaconda3/envs/ko3.7/lib/python3.7/site-packages/sklearn/utils/__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence\n",
      "/home/bax/anaconda3/envs/ko3.7/lib/python3.7/site-packages/sklearn/model_selection/_split.py:18: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable\n",
      "/home/bax/anaconda3/envs/ko3.7/lib/python3.7/site-packages/sklearn/model_selection/_search.py:16: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, namedtuple, defaultdict, Sequence\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kobert import get_tokenizer\n",
    "from kobert import get_pytorch_kobert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /mnt/c/Users/BAX/desktop/psb/biz/kobert_ori/.cache/kobert_v1.zip\n",
      "using cached model. /mnt/c/Users/BAX/desktop/psb/biz/kobert_ori/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model(cachedir=\".cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /mnt/c/Users/BAX/desktop/psb/biz/kobert_ori/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=6,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        else:\n",
    "            out = pooler\n",
    "        return self.classifier(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './model_parameter_score/'\n",
    "model_01 = torch.load(PATH + 'KeyActivities01.pt')\n",
    "model_01.load_state_dict(torch.load(PATH + 'KeyActivities01_state_dict.pth'))\n",
    "\n",
    "model_02 = torch.load(PATH + 'KeyActivities02.pt')\n",
    "model_02.load_state_dict(torch.load(PATH + 'KeyActivities02_state_dict.pth'))\n",
    "\n",
    "model_03 = torch.load(PATH + 'KeyActivities03.pt')\n",
    "model_03.load_state_dict(torch.load(PATH + 'KeyActivities03_state_dict.pth'))\n",
    "\n",
    "max_len = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(vals, idx):\n",
    "    valscpu = vals.cpu().detach().squeeze(0)\n",
    "    a = 0\n",
    "    for i in valscpu:\n",
    "        a += np.exp(i)\n",
    "    return ((np.exp(valscpu[idx]))/a).item() * 100\n",
    "\n",
    "def testModel(model, seq):\n",
    "    cate = [0,1,2,3,4,5]\n",
    "    tmp = [seq]\n",
    "    transform = nlp.data.BERTSentenceTransform(tok, max_len, pad=True, pair=False)\n",
    "    tokenized = transform(tmp)\n",
    "\n",
    "    model.eval()\n",
    "    result = model(torch.tensor([tokenized[0]]).to(device).long(), [tokenized[1]], torch.tensor(tokenized[2]).to(device).long())\n",
    "    idx = result.argmax().cpu().item()\n",
    "    # print(\"점수는\", cate[idx] * 16)\n",
    "    # print(\"신뢰도는:\", \"{:.2f}%\".format(softmax(result,idx)))\n",
    "    return cate[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "입력된 문장 : 자동차 업계관련 된 협력업체 및 파트너를 모집하여 \n",
      "실적유발시 커미션을 지급하고 이에 만족감을 느끼게 하여 \n",
      "홍보도 병행할 수 있게 한다\n",
      "--------------------------------------------------\n",
      "1. 계획서의 핵심자원은 경쟁자들이 복제하기 어려운가?   48/80\n",
      "2. 자원 수요가 예측 가능한가?                         4/10\n",
      "3. 계획서의 핵심자원을 적재적소에 효율적으로 배치했는가? 4/10\n",
      "KeyActivity 총점 : 56/100\n"
     ]
    }
   ],
   "source": [
    "# testModel(model,\"\")\n",
    "sequence = \"자동차 업계관련 된 협력업체 및 파트너를 모집하여 \\n실적유발시 커미션을 지급하고 이에 만족감을 느끼게 하여 \\n홍보도 병행할 수 있게 한다\"\n",
    "key01 = testModel(model_01, sequence)\n",
    "key02 = testModel(model_02, sequence)\n",
    "key03 = testModel(model_03, sequence)\n",
    "\n",
    "print('-'*50)\n",
    "print(f'입력된 문장 : {sequence}')\n",
    "print('-'*50)\n",
    "print(f'1. 계획서의 핵심자원은 경쟁자들이 복제하기 어려운가?   {key01*16}/80')\n",
    "print(f'2. 자원 수요가 예측 가능한가?                         {key02*2}/10')\n",
    "print(f'3. 계획서의 핵심자원을 적재적소에 효율적으로 배치했는가? {key03*2}/10')\n",
    "print(f'KeyActivity 총점 : {key01*16+key02*2+key03*2}/100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ko3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6d4359ad63d4152f22b20fc8f1cc52e44b05340ab2136b0d643bdcf3325e068"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
